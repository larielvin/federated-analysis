{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concrete.ml.deployment.fhe_client_server import FHEModelClient\n",
    "\n",
    "REPO_DIR = Path.cwd()\n",
    "DEPLOYMENT_DIR = REPO_DIR / \"deployment_files\" / \"model\"     # report.json + client.zip + preprocessors\n",
    "REPORT_PATH = DEPLOYMENT_DIR / \"report.json\"\n",
    "\n",
    "CLIENT_FILES = (REPO_DIR / \"client_files\").resolve()\n",
    "CLIENT_FILES.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "FHE_KEYS_DIR = (REPO_DIR / \".fhe_keys\").resolve()\n",
    "FHE_KEYS_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------- Small helpers ---------------------\n",
    "def _short_hex(b: bytes, n: int = 500, shift: int = 100) -> str:\n",
    "    return b[shift:shift + n].hex()\n",
    "\n",
    "def _ensure_dir(p: Path) -> Path:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def load_json(p: Path) -> Dict[str, Any]:\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing JSON at {p}\")\n",
    "    return json.loads(p.read_text())\n",
    "\n",
    "def load_pkl(p: Path):\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(f\"Missing pickle at {p}\")\n",
    "    with p.open(\"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def to_bool(x) -> float:\n",
    "    \"\"\"Return 1.0/0.0 from diverse truthy/falsey tokens; raise on ambiguity.\"\"\"\n",
    "    if isinstance(x, (bool, np.bool_)):\n",
    "        return 1.0 if bool(x) else 0.0\n",
    "    s = str(x).strip().lower()\n",
    "    if s in {\"true\",\"t\",\"1\",\"yes\",\"y\"}:  return 1.0\n",
    "    if s in {\"false\",\"f\",\"0\",\"no\",\"n\"}:  return 0.0\n",
    "    # numeric fallback (explicit)\n",
    "    try:\n",
    "        return 0.0 if float(s) == 0.0 else 1.0\n",
    "    except Exception:\n",
    "        raise ValueError(f\"Boolean field not parseable: {x!r}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- Multi-input client (pads then encrypts one slice) ------------------\n",
    "class MultiInputsFHEModelClient(FHEModelClient):\n",
    "    def __init__(self, path_dir: Path, key_dir: Path, nb_inputs: int):\n",
    "        self.nb_inputs = nb_inputs\n",
    "        super().__init__(path_dir, key_dir=key_dir)\n",
    "\n",
    "    @property\n",
    "    def total_width(self) -> int:\n",
    "        if not hasattr(self.model, \"input_quantizers\") or self.model.input_quantizers is None:\n",
    "            raise RuntimeError(\"Model has no input_quantizers; ensure it was compiled.\")\n",
    "        return len(self.model.input_quantizers)\n",
    "\n",
    "    def quantize_encrypt_slice(self, x_slice: np.ndarray, input_index: int, party_slice: slice) -> bytes:\n",
    "        if x_slice.ndim != 2 or x_slice.shape[0] != 1:\n",
    "            raise ValueError(f\"x_slice must be (1, n_cols); got {x_slice.shape}\")\n",
    "\n",
    "        total = self.total_width\n",
    "        start, stop = party_slice.start, party_slice.stop\n",
    "        if start is None or stop is None:\n",
    "            raise ValueError(\"party_slice must have start/stop.\")\n",
    "        if stop > total:\n",
    "            raise ValueError(f\"party_slice.stop={stop} exceeds model width {total}\")\n",
    "        if (stop - start) != x_slice.shape[1]:\n",
    "            raise ValueError(f\"Slice width mismatch: expects {stop-start}, got {x_slice.shape[1]}\")\n",
    "\n",
    "        pad = np.zeros((1, total), dtype=float)\n",
    "        pad[:, party_slice] = x_slice\n",
    "\n",
    "        q_full = self.model.quantize_input(pad)   # int64 quantized full vector\n",
    "        q_slice = q_full[:, party_slice]\n",
    "\n",
    "        q_inputs = [None] * self.nb_inputs\n",
    "        q_inputs[input_index] = q_slice\n",
    "\n",
    "        enc_tuple = self.client.encrypt(*q_inputs)\n",
    "        return enc_tuple[input_index].serialize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- Verification using report[\"features\"] ------------------------------\n",
    "def verify_party_alignment(report: Dict[str, Any], party: str, preproc) -> slice:\n",
    "    \"\"\"Check that the current preprocessor names match saved names, return saved slice.\"\"\"\n",
    "    features = report[\"features\"]\n",
    "    per_party = features[\"per_party_features\"]\n",
    "    if party not in per_party:\n",
    "        raise ValueError(f\"Party '{party}' missing in features.per_party_features.\")\n",
    "\n",
    "    saved_names = per_party[party][\"feature_names_out\"]\n",
    "    saved_start, saved_stop = per_party[party][\"slice\"]\n",
    "\n",
    "    cols = (\n",
    "        report[\"group_columns\"][party][\"numeric\"]\n",
    "        + report[\"group_columns\"][party][\"categorical\"]\n",
    "        + report[\"group_columns\"][party][\"boolean\"]\n",
    "    )\n",
    "    try:\n",
    "        names_now = preproc.get_feature_names_out().tolist()\n",
    "    except Exception:\n",
    "        # Fallback: transform a NA row to get width only, synthesize names\n",
    "        df = pd.DataFrame([{c: np.nan for c in cols}], columns=cols)\n",
    "        w = int(preproc.transform(df).shape[1])\n",
    "        names_now = [f\"col_{i}\" for i in range(w)]\n",
    "\n",
    "    if len(saved_names) != len(names_now) or saved_names != names_now:\n",
    "        raise RuntimeError(\n",
    "            f\"[{party}] post-processed feature order drift detected.\\n\"\n",
    "            f\"Saved width={len(saved_names)}, now={len(names_now)}.\\n\"\n",
    "            f\"First few saved: {saved_names[:8]}\\nFirst few now  : {names_now[:8]}\"\n",
    "        )\n",
    "    return slice(saved_start, saved_stop)\n",
    "\n",
    "def preprocess_encrypt_send_party(\n",
    "    client_id: str,\n",
    "    party: str,\n",
    "    raw_row: Dict[str, Any],\n",
    "    *,\n",
    "    deployment_dir: Path = DEPLOYMENT_DIR,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Require ALL features for the party to be present. Refuse if any missing or extras.\n",
    "    \"\"\"\n",
    "    report = load_json(deployment_dir / \"report.json\")\n",
    "    parties = report[\"features\"][\"party_order\"]\n",
    "    if party not in parties:\n",
    "        raise ValueError(f\"Party '{party}' not in party_order: {parties}\")\n",
    "\n",
    "    nums = report[\"group_columns\"][party][\"numeric\"]\n",
    "    cats = report[\"group_columns\"][party][\"categorical\"]\n",
    "    bools = report[\"group_columns\"][party][\"boolean\"]\n",
    "    expected = nums + cats + bools\n",
    "\n",
    "    # Check for missing/extras BEFORE coercion\n",
    "    provided = list(raw_row.keys())\n",
    "    missing = [c for c in expected if c not in raw_row]\n",
    "    extras  = [c for c in provided if c not in expected]\n",
    "    if missing or extras:\n",
    "        msg = []\n",
    "        if missing: msg.append(f\"missing={missing}\")\n",
    "        if extras:  msg.append(f\"unexpected={extras}\")\n",
    "        raise ValueError(f\"[{party}] strict input check failed: \" + \"; \".join(msg))\n",
    "\n",
    "    # Coerce types strictly; raise if any field cannot be parsed\n",
    "    coerced: Dict[str, Any] = {}\n",
    "    # numeric → float (no NaN allowed here)\n",
    "    for c in nums:\n",
    "        v = raw_row[c]\n",
    "        try:\n",
    "            coerced[c] = float(v)\n",
    "        except Exception:\n",
    "            raise ValueError(f\"[{party}] numeric field '{c}' not parseable: {v!r}\")\n",
    "    # categorical → string (empty disallowed)\n",
    "    for c in cats:\n",
    "        v = raw_row[c]\n",
    "        s = str(v).strip()\n",
    "        if s == \"\":\n",
    "            raise ValueError(f\"[{party}] categorical field '{c}' is empty\")\n",
    "        coerced[c] = s\n",
    "    # boolean → float in {0.0, 1.0}\n",
    "    for c in bools:\n",
    "        coerced[c] = to_bool(raw_row[c])\n",
    "\n",
    "    # Load preprocessor and verify alignment/slice\n",
    "    preproc = load_pkl(Path(report[\"preprocessors\"][party]))\n",
    "    party_slice = verify_party_alignment(report, party, preproc)\n",
    "\n",
    "    # Preprocess exactly in training column order\n",
    "    df_raw = pd.DataFrame([coerced], columns=expected)\n",
    "    x_post = preproc.transform(df_raw)\n",
    "    x_post = np.asarray(x_post, dtype=float)\n",
    "\n",
    "    # Encrypt only this party slice\n",
    "    key_dir = _ensure_dir(FHE_KEYS_DIR / client_id)\n",
    "    client = MultiInputsFHEModelClient(deployment_dir, key_dir=key_dir, nb_inputs=len(parties))\n",
    "    enc_bytes = client.quantize_encrypt_slice(\n",
    "        x_slice=x_post,\n",
    "        input_index=parties.index(party),\n",
    "        party_slice=party_slice,\n",
    "    )\n",
    "\n",
    "    out_dir = _ensure_dir(CLIENT_FILES / client_id)\n",
    "    out_path = out_dir / f\"encrypted_inputs_{party}\"\n",
    "    with out_path.open(\"wb\") as f:\n",
    "        f.write(enc_bytes)\n",
    "\n",
    "    print(\n",
    "        f\"[{party}] client_id={client_id} → {out_path.name} ({out_path.stat().st_size} bytes) | \"\n",
    "        f\"slice={party_slice.start}:{party_slice.stop} (total={client.total_width})\"\n",
    "    )\n",
    "    return _short_hex(enc_bytes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_rows_from_report(report: Dict[str, Any]) -> Dict[str, Dict[str, Any]]:\n",
    "    gc = report[\"group_columns\"]\n",
    "    samples: Dict[str, Dict[str, Any]] = {}\n",
    "\n",
    "    samples[\"agritech\"] = {\n",
    "        \"farm_area_ha\": 1.6,\n",
    "        \"input_cost_kes\": 45000,\n",
    "        \"agritech_score\": 0.72,\n",
    "        \"mpesa_txn_count_90d\": 42,\n",
    "        \"mpesa_inflow_kes_90d\": 150000,\n",
    "        \"eo_ndvi_gs\": 0.51,\n",
    "        \"crop_primary\": \"maize\",\n",
    "        \"crop_secondary\": \"beans\",\n",
    "        \"irrigated\": 0,\n",
    "    }\n",
    "    samples[\"bank\"] = {\n",
    "        \"loan_amount_kes\": 250000,\n",
    "        \"tenor_months\": 12,\n",
    "        \"interest_rate_pct\": 14.0,\n",
    "        \"prior_default\": 0,\n",
    "    }\n",
    "    samples[\"processor\"] = {\n",
    "        \"yield_t_ha\": 2.2,\n",
    "        \"sales_kes\": 180000,\n",
    "        \"processor_contract\": 1,\n",
    "    }\n",
    "    samples[\"insurance\"] = {\n",
    "        \"climate_risk_index\": 0.33,\n",
    "        \"insured\": 1,\n",
    "    }\n",
    "    samples[\"government\"] = {\n",
    "        \"rain_mm_gs\": 520.0,\n",
    "        \"soil_quality_index\": 0.58,\n",
    "        \"county\": \"Nakuru\",\n",
    "        \"gov_subsidy\": 0,\n",
    "    }\n",
    "    return samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[agritech] client_id=427684149 → encrypted_inputs_agritech (508416 bytes) | slice=0:31 (total=90)\n",
      "[bank] client_id=427684149 → encrypted_inputs_bank (65832 bytes) | slice=31:35 (total=90)\n",
      "[processor] client_id=427684149 → encrypted_inputs_processor (49440 bytes) | slice=35:38 (total=90)\n",
      "[insurance] client_id=427684149 → encrypted_inputs_insurance (33048 bytes) | slice=38:40 (total=90)\n",
      "[government] client_id=427684149 → encrypted_inputs_government (819864 bytes) | slice=40:90 (total=90)\n",
      "\n",
      "Hex previews (truncated):\n",
      "  agritech  : 1698b8b644954a5eb058774c6952bd96a19a41b8d873abb6b0d7cdde28f3d8e9...\n",
      "  bank      : 99dcda3aa921a9115c2163b7a38b50ff454b166ae4c05244c36682af2180b91e...\n",
      "  processor : 17af52b72d9cc98927027c6ab8c341fd57a1ce18c034877481fceebace32e984...\n",
      "  insurance : f31498a6164f8c6fd83bb9197445464ae360c5bd9a204a115aceed3bb1fc7729...\n",
      "  government: feea646c33f30bebbbfcc751532bde3b3701acbd0c6b490f82dd552bfd71559b...\n"
     ]
    }
   ],
   "source": [
    "report = load_json(REPORT_PATH)\n",
    "client_id = None # 4091376614\n",
    "# If client_id is not specified, pick the first numerical subdirectory in CLIENT_FILES\n",
    "if 'client_id' not in locals() or not client_id:\n",
    "    subdirs = [d for d in os.listdir(CLIENT_FILES) if (CLIENT_FILES / d).is_dir() and d.isdigit()]\n",
    "    if subdirs:\n",
    "        client_id = subdirs[0]\n",
    "    else:\n",
    "        raise ValueError(\"No numerical client_id subdirectory found in CLIENT_FILES.\")\n",
    "\n",
    "previews: Dict[str, str] = {}\n",
    "\n",
    "rows = sample_rows_from_report(report)\n",
    "for party in report[\"features\"][\"party_order\"]:\n",
    "    previews[party] = preprocess_encrypt_send_party(\n",
    "        client_id=client_id,\n",
    "        party=party,\n",
    "        raw_row=rows[party],\n",
    "    )\n",
    "\n",
    "# bank_row = {\n",
    "#     \"loan_amount_kes\": \"5675\",\n",
    "#     \"tenor_months\": 12,\n",
    "#     \"interest_rate_pct\": 14.0,\n",
    "#     \"prior_default\": 0,\n",
    "# }\n",
    "# previews_bank = preprocess_encrypt_send_party(\n",
    "#     client_id=client_id, \n",
    "#     party=\"bank\", \n",
    "#     raw_row=bank_row\n",
    "# )\n",
    "# previews[\"bank (alt)\"] = previews_bank\n",
    "\n",
    "print(\"\\nHex previews (truncated):\")\n",
    "for p, h in previews.items():\n",
    "    print(f\"  {p:10s}: {h[:64]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fedanalysisenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
